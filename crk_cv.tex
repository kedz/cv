%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Classicthesis-Styled CV
% LaTeX Template
% Version 1.0 (22/2/13)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Alessandro Plasmati
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%------------------------------------------------------------------------------

\documentclass{scrartcl}

% Write Section Titles in the left margin.
\reversemarginpar 
\newcommand{\MarginSection}[1]{\marginpar{#1}} 

\usepackage[nochapters]{classicthesis} 
\usepackage[LabelsAligned]{currvita} 

\usepackage{geometry}
\geometry{a4paper, left=1.5in, top=1in, right=1in}

\renewcommand{\cvheadingfont}{\LARGE\color{Maroon}} 
\usepackage{hyperref} 
\usepackage{graphicx}
\hypersetup{colorlinks, breaklinks, urlcolor=Maroon, linkcolor=Maroon} 

\newlength{\datebox}\settowidth{\datebox}{Spring 2011} % Set the width of the date box in each block

\newcommand{\NewEntry}[2]{\noindent\hangindent=0em\hangafter=0 \parbox{4em}{\small #1} #2 
\vspace{0.35em}} % Add some white space after each new entry



\newcommand{\PubEntry}[5]{\noindent\hangindent=0em\hangafter=0 #1. \href{#2}{\color{#5}{#3.}} {\textit{#4.}}\\} 

%\newcommand{\Description}[1]{\hangindent=2em\hangafter=0\noindent\raggedright\footnotesize{#1}\par\normalsize\vspace{1em}} % Define a command for descriptions of each entry - change spacing and font sizes here

%----------------------------------------------------------------------------------------

\begin{document}

\thispagestyle{empty} % Stop the page count at the bottom of the first page

%----------------------------------------------------------------------------------------
%	NAME AND CONTACT INFORMATION SECTION
%----------------------------------------------------------------------------------------

\begin{cv}{\spacedallcaps{Chris Kedzie}}\vspace{0.5em} % Your name

\noindent\spacedlowsmallcaps{Curriculum Vitae}\vspace{0.5em} 

\NewEntry{phone}{+1 (925) 323 1837}

\NewEntry{email}{\href{mailto:kedzie@cs.columbia.edu}{kedzie@cs.columbia.edu}}

\NewEntry{web}{\href{http://www.cs.columbia.edu/~kedzie}{www.cs.columbia.edu/$\sim$kedzie}}

\NewEntry{~~~}{\href{https://www.linkedin.com/in/christopher-kedzie-39b03131}{\includegraphics[scale=.01]{linkedin.jpg} LinkedIn} $\cdot$ \href{https://github.com/kedz}{\includegraphics[scale=0.5]{github.pdf} Github} $\cdot$ \href{https://scholar.google.com/citations?hl=en&user=-xcIYgsAAAAJ}{\includegraphics[scale=0.035]{googlescholar.jpg} Google Scholar}
} 

~\\

\MarginSection{~\\Research\\Statement} 
I am interested in computational models of natural language understanding 
and generation. I am actively investigating methods for 
improving neural language models via interaction with secondary 
models of semantics
and/or syntactic structure. Human language use exhibits tremendous 
productivity (in the sense of Chomsky, i.e. ``making infinite use of finite means''), while neural models are frequently poor generalizers of language 
data, often learning non-hierarchical or otherwise 
idiosyncratic representations. 
In the hopes of improving this situation, 
I am also investigating topics in differentiable data structures 
(e.g., stacks or addressable memory) and 
model regularization using adversarial and cooperative learning tasks
to encourage more systematic and explainable model behavior.

I also apply machine learning to natural language data
to make useful predictions, such as predicting the importance 
of text for summarization or extracting signals
from the web for social scientists.





 
%In my Ph.D. thesis focused on estimating the 


%I am a Ph.D. candidate in the Department of Computer Science at Columbia 
%Universityprimarily 
%focusing on problems in text summarization and natural language generation.


 ~\\

%------------------------------------------------------------------------------
%	EDUCATION
%------------------------------------------------------------------------------

{\noindent\hangindent=0em\hangafter=0 \MarginSection{Education}\textbf{Columbia University}

 \noindent\hangindent=2em\hangafter=0 2014-pres. Ph.D., Computer Science 

\noindent\hangindent=6.8em\hangafter=0 Advisor: Kathleen McKeown

\noindent\hangindent=6.8em\hangafter=0 Thesis: \textit{Salience Estimation and Faithful Generation: Modeling Methods for}

\noindent\hangindent=10.2em\hangafter=0 \textit{Text Summarization and Generation}


\noindent\hangindent=2em\hangafter=0 2014-2018 M.Phil., Computer Science 

\noindent\hangindent=2em\hangafter=0 2012-2014 M.S., Computer Science 

}

{~\vspace{-1.25em}\\}

{\noindent\hangindent=0em\hangafter=0 \textbf{Loyola Marymount University} }

{\noindent\hangindent=2em\hangafter=0 2004-2008 B.A., Music \& Recording Arts Double Major

}

%\spacedlowsmallcaps{Publications}\vspace{1em}


%\NewEntry{Nov. 2018}{Chris Kedzie, Kathleen McKeown, and Hal Daum\'e III. 
%    \textit{Content Selection in Deep Learning Models of Summarization}}

    
~\\


\MarginSection{~\\Research\\Experience}\noindent\hangindent=2em\hangafter=1 Research Intern, \textbf{Facebook Research}, Summer 2017.\\
%\NewEntry{Summer 2017}{Research Intern, \textsc{Facebook} Applied Machine Learning (AML)}
%\Description{\MarginText{Facebook Research}

{~\vspace{-3.5em}\\}

\noindent\hangindent=2em\hangafter=0 I interned with Umut Ozertem in the 
Applied Machine Learning (AML) group, focusing on click bait and hate speech 
detection.
During my project, I developed an adversarial training method to improve 
performance of our convolutional neural network text classifiers.
I implemented this architecture in PyTorch and Caffe2, and integrated it into
the internal FBLearner system for tracking and running experiments.
My project is currently in use by several teams in the AML group, and is currently under submission for a patent.

{~\vspace{-1.5em}\\}

\noindent\hangindent=2em\hangafter=1 Research Intern, \textbf{Microsoft Research}, Summer 2015.\\

{~\vspace{-3.5em}\\}

\noindent\hangindent=2em\hangafter=0 I interned with Fernando Diaz in 
    New York City, continuing our collaboration on streaming 
    news summarization. I developed scalable summarization systems 
    to provide users with brief updates of news events as they were unfolding. 
    We participated in the Temporal Summarization Track of the 2015
    Text Retrieval Conference, where we were the top performer, and invited
to give a talk.



\newcommand{\nlgcolor}{Maroon}
\newcommand{\extsumcolor}{RoyalPurple}
\newcommand{\socialnlpcolor}{magenta}

~\\

\MarginSection{~\\Selected\\Publications}  

\PubEntry{\textbf{Chris Kedzie} and Kathleen McKeown}{
    http://www.cs.columbia.edu/~kedzie/inlga.pdf}{A Good Sample is Hard to Find: Noise Injection Sampling and Self-Training for Neural Language Generation Models}{Under submission}{\nlgcolor}

    \MarginSection{~\\\color{\nlgcolor}{\footnotesize \vspace{-0.4em}Controllable\\\vspace{-0.4em}Language\\\vspace{-0.4em}Generation}}

\PubEntry{Katy Gero, \textbf{Chris Kedzie}, Jonathan Reeve, and Lydia Chilton}{
    http://www.cs.columbia.edu/~kedzie/inlgb.pdf}{Low-Level Linguistic Controls for Style Transfer and Content Preservation}{Under submission}{\nlgcolor}

    \MarginSection{\color{\extsumcolor}{\footnotesize ~\vspace{-0.0em}\\\vspace{-0.4em}Automatic Text\\Summarization}}

\PubEntry{\textbf{Chris Kedzie}, Kathleen McKeown, and Hal Daum\'e III}{https://arxiv.org/pdf/1810.12343}{Content Selection in Deep Learning Models of Summarization}{EMNLP 2018}{\extsumcolor}

\PubEntry{\textbf{Chris Kedzie}, Fernando Diaz, and Kathleen McKeown}{https://arxiv.org/pdf/1605.03664.pdf}{Real-Time Web Scale Event Summarization Using Sequential Decision Making}{IJCAI 2016}{\extsumcolor}

\PubEntry{\textbf{Chris Kedzie}, Kathleen McKeown, and Fernando Diaz}{https://www.aclweb.org/anthology/P15-1155.pdf}{Predicting Salient Updates for Disaster Summarization}{ACL 2015}{\extsumcolor}

    \MarginSection{\color{\socialnlpcolor}{\footnotesize ~\vspace{-0.0em}\\\vspace{-0.4em}NLP for Social\\Science}}

\PubEntry{Philipp Blandfort, Desmond U. Patton, William R. Frey, Svebor Karaman, Surabhi Bhargava, Fei-Tzin Lee, Siddharth Varia, \textbf{Chris Kedzie}, Michael B. Gaskell, Rossano Schifanella, Kathleen McKeown, Shih-Fu Chang}{https://www.aaai.org/ojs/index.php/ICWSM/article/download/3214/3082}{Multimodal social media analysis for gang violence prevention}{ICWSM 2019}{\socialnlpcolor}

\PubEntry{Serina Chang, Ruiqi Zhong, Ethan Adams, Fei-Tzin Lee, Siddharth Varia, Desmond U. Patton, William R. Frey, \textbf{Chris Kedzie}, Kathleen McKeown}{https://arxiv.org/pdf/1809.03632}{Detecting gang-involved escalation on social media using context}{EMNLP 2018}{\socialnlpcolor}


\MarginSection{~\\Talks}   

\noindent \parbox{6em}{2018} Agolo.
            
\noindent \parbox{6em}{2016} Machine Learning and Friends Lunch. UMass. Amherst.

\noindent \parbox{6em}{2015} Text Retrieval Conference (TREC), Temporal Summarization Track.

\noindent \parbox{6em}{2014} Text Retrieval Conference (TREC), Temporal Summarization Track.

\noindent \parbox{6em}{~} KDD at Bloomberg: Data Frameworks Track.\\


\MarginSection{~\\Demos}


{\noindent\parbox{6em}{2016}  \textit{Monitoring Large Scale Disasters.} Data Science Day @ Columbia University} \\
 {\noindent\parbox{6em}{~~~~} \noindent  Data Science Institute.} \\

\MarginSection{~\\Doctoral\\Consortium}


{\noindent\parbox{6em}{2016}  \textit{Extractive and Abstractive Event Summarization over Streaming Web Text.}} \\
 {\noindent\parbox{6em}{~~~~} \noindent  IJCAI.}

~\\
\pagebreak

\MarginSection{~\\Summer\\Schools}

{\noindent\parbox{6em}{2016}  Deep Learning Summer School. University of Montreal.} \\ ~\\


\MarginSection{~\\Community\\Service}

{\noindent\parbox{6em}{2016--pres.}  Organizer. Columbia NLP Reading Group.} \\
{\noindent\parbox{6em}{2014--2017}  Organizer. NLP talks at Columbia.} \\
 

\MarginSection{~\\Teaching\\Experience}

{\noindent\parbox{6em}{Spring 2014}  Teaching Assistant. Semantic Technologies in IBM Watson.}\\
{\noindent\parbox{6em}{~~~~~~~~~~~}  Instructor: Alfio Gliozzo.}

~\\ ~\\

%\spacedlowsmallcaps{Talks}\vspace{1em}
%
%
%\NewEntry{Nov. 2018}{Content Selection in Deep Learning Models of Summarization}
%
%\Description{\MarginText{Empirical Methods in Natural Language Processing}I 
%    presented our long-paper submission at the 2018 meeting of the 
%Conference on Empirical Methods in Natural Language Processing in Brussels.
%See associated paper abstract.}
%
%
%
%\NewEntry{Oct. 2016}{Machine Learning and Friends Lunch: Real-Time Web Scale Event Summarization Using
%Sequential Decision Making}
%
%\Description{\MarginText{UMass Amherst}I presented our recent summarization research at the CS department's weekly machine learning talk. 
%See associated paper abstract.}
%
%
%
%
%\NewEntry{July. 2016}{Real-Time Web Scale Event Summarization Using
%Sequential Decision Making}
%
%\Description{\MarginText{International Joint Conference on Artificial Intelligence}I presented our long-paper submission at the 2016 meeting of the 
%International Joint Conference on Artificial Intelligence in New York City. 
%See associated paper abstract.}
%
%
%\NewEntry{Nov. 2015}{Learning 2 Summarize: TREC 2015}
%
%\Description{\MarginText{Temporal Summarization Track, TREC 2015}Abstract: In
%this talk, I present an overview of our participation in the temporal 
%summarization track at the 2015 Text Retrieval Conference. 
%%Using a machine
%%learning based approach to the temporal summarization task is difficult 
%%because 
%Most of the available training data for this task consists of static judgments
%on returned updates, making it difficult to make use of sequential predictions
%in a learned model. I show how we used learning based search
% (SEARN, Learning2Search, LOLS) to sample 
%realistic runs over the training streams and learn from dynamic features
%like previous update decisions and rolling stream observations.  Our 
%resulting system is able to build an event summary in an online fashion
%avoiding latency penalties while still outperforming retrospective 
%approaches (e.g. clustering). 
%\newline
%Joint work with \textsc{Fernando Diaz}.
%}
%
%
%
%
%\NewEntry{July 2015}{Predicting Salient Updates for Disaster Summarization}
%
%\Description{\MarginText{Association of Computational Linguistics} I presented our long-paper
%submission at the 2015 meeting of the Association for Computational Linguistics
%in Beijing, China. See associated paper 
%abstract.}
%
%
%
%
%
%\NewEntry{Nov. 2014}{Columbia U. at TREC: Temporal Summarization}
%
%\Description{\MarginText{Temporal Summarization Track, TREC 2014}Abstract: In
%this talk, I present an overview of our participation in the temporal 
%summarization track at the 2014 Text Retrieval Conference. Our 
%submission was one of the top overall submissions for this track.
%Our performance gain came largely from our precision in the 
%summary update selection stage; I outline the details of our salience
%regression model and affinity propagation clustering architecture, including
%their effect on our scores. I also address our current system shortcomings,
%especially our inability to explicitly control for redundancy.
%\newline
%Joint work with \textsc{Fernando Diaz} \& \textsc{Kathleen McKeown}.
%}
%
%
%\NewEntry{Aug. 2014}{Summarizing Disasters Over Time}
%
%\Description{\MarginText{Bloomberg Data Frameworks Track, KDD 2014}Abstract: We have developed a text summarization system that
%can generate summaries over time from web crawls on disasters. We show that
%our method of identifying exemplar sentences for a summary using affinity
%propagation clustering produces better summaries than clustering based on
%K-medoids as measured using Rouge on a small set of examples. A key component
%of our approach is the prediction of salient information using event related
%features based on location, temporal changes in topic, and two different
%language models.\newline
%Joint work with \textsc{Fernando Diaz} \& \textsc{Kathleen McKeown}.
%}
%
%\vspace{1em} % Extra space between major sections
%
%
%\noindent\spacedlowsmallcaps{Demos}\vspace{1em}
%
%\NewEntry{April 2016}{Monitoring Large Scale Disasters, 
%\textsc{Data Science Day}}
%
%\Description{\MarginText{Columbia University's Data Science Institute}
%During crises such as natural disasters or other human tragedies, information   needs of both civilians and responders often require urgent, specialized   treatment. Monitoring and summarizing important information during such an   event remains a difficult problem. We present a system for monitoring online   news for such disasters. Given a query: e.g. "Hurricane Sandy," our system   analyzes the web, and produces a sequence of updates, brief textual   descriptions about the current state of the event, as that event unfolds   over time.    We use novel, disaster-specific features for generating updates,    including geo-locations and language models representing the language of    disaster.   Our demo will allow users to see updates generated for   pre-run queries including: Hurricane Sandy, the Boston Marathon bombing,   and 40 other large scale disasters.  
%
%}
%
%
%
%
%
%\vspace{1em} % Extra space between major sections
%%\pagebreak 
%\noindent\spacedlowsmallcaps{Doctoral Consortium}\vspace{1em}
%
%\NewEntry{July 2016}{Extractive and Abstractive Event Summarization over Streaming Web Text, \textsc{25th International Joint Conference on Artificial Intelligence}}
%
%\Description{
%~~~~}
%%------------------------------------------------
%
%\vspace{1em} % Extra space between major sections
%
%\noindent\spacedlowsmallcaps{Summer Schools}\vspace{2em}
%
%\NewEntry{August 2016}{Deep Learning Summer School at the University of Montreal}
%
%\Description{
%~~~~}
%%------------------------------------------------
%
%\vspace{1em} % Extra space between major sections
%
%
%
%\noindent\spacedlowsmallcaps{Departmental Activities}\vspace{1em}
%
%\NewEntry{Sept. 2014 -- Sept. 2017}{Organizer, Columbia NLP Talks}
%
%\Description{Coordinate and plan internal and visiting speakers to the NLP 
%group at Columbia.
%}
%\NewEntry{June 2016 -- Present}{Organizer, Columbia NLP Reading Group}
%
%\Description{Coordinate and plan weekly reading group on
%    current research in 
%NLP.
%}
%%------------------------------------------------
%
%\vspace{1em} % Extra space between major sections
%
%
%
%
%
%%----------------------------------------------------------------------------------------
%%	WORK EXPERIENCE
%%----------------------------------------------------------------------------------------
%
%\noindent\spacedlowsmallcaps{Work Experience}\vspace{1em}
%
%
%\NewEntry{Summer 2017}{Research Intern, \textsc{Facebook} Applied Machine Learning (AML)}
%
%\Description{\MarginText{Facebook Research}I interned with Umut Ozertem in the AML group, focusing on click bait and hate speech detection.
%During my project, I developed an adversarial training method to improve 
%performance of our convolutional neural network text classifiers.
%I implemented this architecture in PyTorch and Caffe2, and integrated it into
%the internal FBLearner system for tracking and running experiments.
%My project is currently in use by several teams in the AML group, and is currently under submission for a patent.}
%
%
%\NewEntry{Summer 2015}{Research Intern, \textsc{Microsoft Research}}
%
%\Description{\MarginText{MSR-NYC} I interned with Fernando Diaz at Microsoft
%    Research in New York City, continuing our collaboration on streaming 
%    news summarization. I developed scalable summarization systems 
%    to provide users with brief updates of news events as they were unfolding. 
%    Our work was submitted to the Temporal Summarization Track of the 2015
%    Text Retrieval Conference, where we were a top performer and invited
%to give a talk.}
%
%
%\NewEntry{Spring 2014}{Teacher's Assistant, \textsc{Columbia University}}
%
%\Description{\MarginText{Columbia University}I was the TA for the class 
%\textit{Semantic Technologies in IBM Watson}, taught by IBM researcher 
%\textsc{Alfio Gliozzo}. The class covered the various inner workings of the 
%Jeopardy
%playing computer. My responsibilities included teaching several lectures on
%foundational natural language processing tasks and problems, and an overview
%of the semantic web. Along with Dr. \textsc{Gliozzo}, I helped guide and 
%supervise the
%various student projects, one of which led to a publication at EMNLP 2014.}
%
%%------------------------------------------------
%
%\NewEntry{2008--2011}{Composer's Assistant, \textsc{Stimmung}  --- New York}
%
%\Description{\MarginText{Stimmung \href{http://www.stimmung.tv}{stimmung.tv}}Performed 
%audio engineering/mixing/editing and sheet music preparation for 
%staff composers in a busy commercial music and sound post-production studio.
%Posted and presented work to clients. Provided general office support and
%correspondence. Organized and archived audio and video assets. 
%Coordinated asset delivery to
%clients/post-production services. 
%Worked on many CLEO and Emmy award winning commercial
%campaigns including several Super Bowl spots for such clients as: Coca-Cola, 
%Mercedes-Benz, Kia, Levi's, and Monster.com.
%In addition to commercials, I also helped produce music for several
%independent films, documentaries, and television shows including 
%\textit{Reagan} (HBO), \textit{The Rising: Rebuilding Ground Zero} (Discovery Communications), and \textit{Journey to the Stars} (Hayden Planetarium, 
%American Museum of Natural History).  
% }
%
%%------------------------------------------------
%
%\NewEntry{2006-2008}{Production Director, \textsc{KXLU} --- Los Angeles}
%
%\Description{\MarginText{KXLU 88.9FM \href{http://www.kxlu.com}{kxlu.com}}Worked with station directors and staff to plan 
%concerts and events in the Los Angeles area, as well as the annual fundraiser.
%Supervised implementation of a new website. Coordinated the recording and 
%broadcast of all live and pre-recorded performances and interviews
%at the station. Managed and researched equipment upgrades for the KXLU 
%Production Studio. }
%
%% \\ Reference: Big \textsc{Mike}\ \ +1 (000) 111 1111\ \ $\cdotp$\ \ \href{mailto:mike@buymore.com}{mike@buymore.com}}
%
%%------------------------------------------------
%
%\vspace{1em} % Extra space between major sections
%
%%----------------------------------------------------------------------------------------
%%	EDUCATION
%%----------------------------------------------------------------------------------------
%
%\spacedlowsmallcaps{Education}\vspace{1em}
%
%\NewEntry{2014-Present}{Columbia University}
%
%\Description{\MarginText{PhD}\textit{Natural Language Processing}\ \ $\cdotp$\ \ Dept. of Computer Science\ \ $\cdotp$\ \ \newline Fu Foundation School of Engineering \& Applied Science \newline
%Adviser: Prof.~\textsc{Kathleen McKeown}\\ }
%%Description: 
%%I am a fifth year Ph.D. student, working with Prof. \textsc{McKeown} on event
%%understanding from text data. My research has focused on 
%%automatic news summarization, using trainable models in 
%%a streaming news setting. For the past two years, I have participated in the 
%%Temporal Summarization Track at the Text Retrieval Conference (TREC) and have
%%been invited to present both times. I am generally interested in 
%%regression, ranking, and optimization for content selection, especially when
%%applied to automatic summary generation. With Prof. \textsc{McKeown} and 
%%\textsc{Fernando Diaz} at Microsoft Research, I have applied these techniques 
%%to the domain of man-made and natural disaster news.}
%
%%With Prof. \textsc{McKeown}, I am working on event understanding from 
%%newswire and social media text. Specifically, we are exploring techniques
%%for automatically summarizing natural disasters, acts of terrorism, and 
%%other large-scale, catastrophic events. I am currently working on the learning
%%of sentence representations and similarity methods that take into account 
%%event causality and correlation for use in text clustering.
%%With Prof. \textsc{McKeown} and Dr. \textsc{Fernando Diaz} at Microsoft Research, I 
%%participated in the Text Retrieval Conference Temporal Summarization track,
%%where I experimented with regression methods for predicting important 
%%information to be included in automatically generated summaries.
%%I am also overseeing a masters student and two undergraduate students in an
%%effort to modernize Prof. \textsc{McKeown's} automatic news summarization 
%%system, Newsblaster. }
%
%%------------------------------------------------
%
%\NewEntry{2013-2014}{Columbia University}
%
%\Description{\MarginText{Master of Science}GPA: 3.87\ \ $\cdotp$\ \ \textit{Natural Language Processing}\ \ $\cdotp$\ \ Dept. of Computer Science\ \ $\cdotp$\ \ \newline Fu Foundation School of Engineering \& Applied Science \newline
%Adviser: Prof.~\textsc{Kathleen McKeown}\\ }
%%Description: 
%%I continued to pursue my interests in natural language processing, 
%%in addition to
%%machine learning and statistics. In Prof. \textsc{McKeown's} lab I worked on
%%question-answering (QA) for the DARPA BOLT (Broad Operational Language 
%%Translation) project. My research focused on unsupervised methods of 
%%text similarity and the application of semantic web/linked open data for QA.}
%
%
%\NewEntry{2012-2013}{Columbia University}
%
%\Description{GPA: 3.95\ \ $\cdotp$\ \ \textit{Post Baccalaureate Studies}\ \ $\cdotp$\ \ School of Continuing Education \newline
%Description: 
%While taking introductory courses in computer science, I also worked as a 
%research assistant for Prof. \textsc{Kathleen McKeown} and her student, 
%\textsc{Sara Rosenthal}.
%Responsibilities included annotating research corpora for
%supervised learning systems, developing web crawlers to extract user discussions from online forums, and building research corpora for studies in 
%automatic influence and agreement detection in natural
%language.}
%
%\NewEntry{2011}{Baruch College, CUNY}
%
%\Description{GPA: 4.0\ \ $\cdotp$\ \ Continuing \& Professional Studies \newline
%Description: I took two classes on Java and Oracle SQL development.}
%
%\NewEntry{2004-2008}{Loyola Marymount University}
%
%\Description{\MarginText{Bachelor of Arts}GPA: 3.34\ \ $\cdotp$\ \ \textit{Music/Recording Arts Double Major}\ \ $\cdotp$\ \ College of Communication and Fine Arts/School of Film and Television\newline }
%%Description: In my undergraduate degree, I pursued interests in both classical
%%music and sound design/mixing for film. Within the music department, I 
%%concetrated on
%%music theory/composition as well as guitar performance, culminating in two
%%senior theses, an original composition, \textit{String Quartet for Space
%%Travel}, and a guitar recital, featuring works by Antonio Lauro, Roland Dyens,
%%Leo Brouwer, Miguel Llobet, Antonio Vivaldi, and others. Within the film
%%department, I scored and sound designed/mixed many student films 
%%(\textit{The Cannibal Ad}, Golden Hamster(Best Overall) Award 
%%and 1$^{st}$ Place for Narrative Short, 2005 Northwest Projections Film 
%%Festival; \textit{Lily}, Best Sound, Best Film, 2007 LMU School of Film and Television ``Film Outside the
%%Frame Festival.'').}
%
%
%
%
%%------------------------------------------------
%
%\vspace{1em} % Extra space between major sections
%
%
%
%
%%----------------------------------------------------------------------------------------
%%	COMPUTER SKILLS
%%----------------------------------------------------------------------------------------
%
%\spacedlowsmallcaps{Computer Skills}\vspace{1em}
%
%%\Description{\MarginText{Application Areas}Automatic Summarization, Text Clustering, Text Representation \& Feature Learning, Machine Learning, Data Mining, Web Scraping}
%
%\Description{\MarginText{Languages (Adept)}English, \textsc{c/c++}, \textsc{python}, \textsc{lua}, \textsc{java}, \textsc{perl}, \textsc{html}, \LaTeX}
%\Description{\MarginText{Languages (Familiar)}Latin, \textsc{matlab}, \textsc{X10}, \textsc{javascript}, \textsc{SQL}, \textsc{SPARQL}, \textsc{Linux}/\textsc{Bash}/shell scripting}
%
%\Description{\MarginText{Machine Learning Frameworks}PyTorch, LuaTorch, TensorFlow, Caffe2, Theano, Scientific Python Stack (Numpy, Scipy, SciKit-Learn, iPython/Jupyter Notebook, etc.), VowpalWabbit}
%
%%------------------------------------------------
%
%\vspace{1em} % Extra space between major sections
%
%%----------------------------------------------------------------------------------------
%%	OTHER INFORMATION
%%----------------------------------------------------------------------------------------
%
%\spacedlowsmallcaps{Other Information}\vspace{1em}
%
%%\Description{\MarginText{Awards}2011\ \ $\cdotp$\ \ School of Business Postgraduate Scholarship}
%
%%\vspace{-0.5em} % Negative vertical space to counteract the vertical space between every \Description command
%
%%\Description{2010\ \ $\cdotp$\ \ Top Achiever Award -- Commerce}
%
%%------------------------------------------------
%
%%\vspace{1em}
%
%%\Description{\MarginText{Communication Skills}2010\ \ $\cdotp$\ \ Oral Presentation at the California Business Conference}
%
%%\vspace{-0.5em} % Negative vertical space to counteract the vertical space between every \Description command
%
%%\Description{2009\ \ $\cdotp$\ \ Poster at the Annual Business Conference in Oregon}
%
%%------------------------------------------------
%
%%\vspace{1em}
%
%%\newlength{\langbox} % Create a new length for the length of languages to keep them equally spaced
%%\settowidth{\langbox}{English} % Length equals the length of "English" - if you have a longer language in your list put it here
%
%%\Description{\MarginText{Languages}\parbox{\langbox}{\textsc{English}}\ \ $\cdotp$\ \ \ Mothertongue}
%
%%\vspace{-0.5em} % Negative vertical space to counteract the vertical space between every \Description command
%
%%\Description{\parbox{\langbox}{\textsc{Spanish}}\ \ $\cdotp$\ \ \ Intermediate (conversationally fluent)}
%
%%\vspace{-0.5em} % Negative vertical space to counteract the vertical space between every \Description command
%
%%\Description{\parbox{\langbox}{\textsc{Dutch}}\ \ $\cdotp$\ \ \ Basic (simple words and phrases only)}
%
%%\vspace{1em} % Negative vertical space to counteract the vertical space between every \Description command
%
%%------------------------------------------------
%
%\Description{\MarginText{Interests}Experimental Music\ \ $\cdotp$\ \ Pop Music\ \ $\cdotp$\ \ Punk Rock}
%
%----------------------------------------------------------------------------------------

\date{}

\end{cv}

\end{document}
